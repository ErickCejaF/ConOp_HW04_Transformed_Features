{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Example 1: Symbolic Regressor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.utils.random import check_random_state\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import graphviz"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "x0 = np.arange(-1, 1, .1)\n",
    "x1 = np.arange(-1, 1, .1)\n",
    "x0, x1 = np.meshgrid(x0, x1)\n",
    "y_truth = x0**2 - x1**2 + x1 - 1\n",
    "\n",
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)\n",
    "ax.set_xticks(np.arange(-1, 1.01, .5))\n",
    "ax.set_yticks(np.arange(-1, 1.01, .5))\n",
    "surf = ax.plot_surface(x0, x1, y_truth, rstride=1, cstride=1, color='green', alpha=0.5)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rng = check_random_state(0)\n",
    "\n",
    "# Training samples\n",
    "X_train = rng.uniform(-1, 1, 100).reshape(50, 2)\n",
    "y_train = X_train[:, 0]**2 - X_train[:, 1]**2 + X_train[:, 1] - 1\n",
    "\n",
    "# Testing samples\n",
    "X_test = rng.uniform(-1, 1, 100).reshape(50, 2)\n",
    "y_test = X_test[:, 0]**2 - X_test[:, 1]**2 + X_test[:, 1] - 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "est_gp = SymbolicRegressor(population_size=5000,\n",
    "                           generations=20, stopping_criteria=0.01,\n",
    "                           p_crossover=0.7, p_subtree_mutation=0.1,\n",
    "                           p_hoist_mutation=0.05, p_point_mutation=0.1,\n",
    "                           max_samples=0.9, verbose=1,\n",
    "                           parsimony_coefficient=0.01, random_state=0)\n",
    "est_gp.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(est_gp._program)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "est_tree = DecisionTreeRegressor()\n",
    "est_tree.fit(X_train, y_train)\n",
    "est_rf = RandomForestRegressor(n_estimators=10)\n",
    "est_rf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_gp = est_gp.predict(np.c_[x0.ravel(), x1.ravel()]).reshape(x0.shape)\n",
    "score_gp = est_gp.score(X_test, y_test)\n",
    "y_tree = est_tree.predict(np.c_[x0.ravel(), x1.ravel()]).reshape(x0.shape)\n",
    "score_tree = est_tree.score(X_test, y_test)\n",
    "y_rf = est_rf.predict(np.c_[x0.ravel(), x1.ravel()]).reshape(x0.shape)\n",
    "score_rf = est_rf.score(X_test, y_test)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "\n",
    "for i, (y, score, title) in enumerate([(y_truth, None, \"Ground Truth\"),\n",
    "                                       (y_gp, score_gp, \"SymbolicRegressor\"),\n",
    "                                       (y_tree, score_tree, \"DecisionTreeRegressor\"),\n",
    "                                       (y_rf, score_rf, \"RandomForestRegressor\")]):\n",
    "\n",
    "    ax = fig.add_subplot(2, 2, i+1, projection='3d')\n",
    "    ax.set_xlim(-1, 1)\n",
    "    ax.set_ylim(-1, 1)\n",
    "    ax.set_xticks(np.arange(-1, 1.01, .5))\n",
    "    ax.set_yticks(np.arange(-1, 1.01, .5))\n",
    "    surf = ax.plot_surface(x0, x1, y, rstride=1, cstride=1, color='green', alpha=0.5)\n",
    "    points = ax.scatter(X_train[:, 0], X_train[:, 1], y_train)\n",
    "    if score is not None:\n",
    "        score = ax.text(-.7, 1, .2, \"$R^2 =\\/ %.6f$\" % score, 'x', fontsize=14)\n",
    "    plt.title(title)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dot_data = est_gp._program.export_graphviz()\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render('images/ex1_child', format='png', cleanup=True)\n",
    "graph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(est_gp._program.parents)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "idx = est_gp._program.parents['donor_idx']\n",
    "fade_nodes = est_gp._program.parents['donor_nodes']\n",
    "print(est_gp._programs[-2][idx])\n",
    "print('Fitness:', est_gp._programs[-2][idx].fitness_)\n",
    "dot_data = est_gp._programs[-2][idx].export_graphviz(fade_nodes=fade_nodes)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Example 2: Symbolic Transformer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gplearn.genetic import SymbolicTransformer\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.datasets import load_diabetes\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rng = check_random_state(0)\n",
    "diabetes = load_diabetes()\n",
    "perm = rng.permutation(diabetes.target.size)\n",
    "diabetes.data = diabetes.data[perm]\n",
    "diabetes.target = diabetes.target[perm]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "est = Ridge()\n",
    "est.fit(diabetes.data[:300, :], diabetes.target[:300])\n",
    "print(est.score(diabetes.data[300:, :], diabetes.target[300:]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "function_set = ['add', 'sub', 'mul', 'div', 'sqrt', 'log',\n",
    "                'abs', 'neg', 'inv', 'max', 'min']\n",
    "gp = SymbolicTransformer(generations=20, population_size=2000,\n",
    "                         hall_of_fame=100, n_components=10,\n",
    "                         function_set=function_set,\n",
    "                         parsimony_coefficient=0.0005,\n",
    "                         max_samples=0.9, verbose=1,\n",
    "                         random_state=0)\n",
    "gp.fit(diabetes.data[:300, :], diabetes.target[:300])\n",
    "\n",
    "gp_features = gp.transform(diabetes.data)\n",
    "new_diabetes = np.hstack((diabetes.data, gp_features))\n",
    "\n",
    "est = Ridge()\n",
    "est.fit(new_diabetes[:300, :], diabetes.target[:300])\n",
    "print(est.score(new_diabetes[300:, :], diabetes.target[300:]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The SymbolicTransformer works slightly differently to the SymbolicRegressor. While the regressor seeks to minimize the error between the programsâ€™ outputs and the target variable based on an error metric, the transformer seeks an indirect relationship that can then be exploited by a second estimator. Essentially, this is automated feature engineering and can create powerful non-linear interactions that may be difficult to discover in conventional methods.\n",
    "\n",
    "Where the regressor looks to minimize the direct error, the transformer looks to maximize the correlation between the predicted value and the target. This is done through either the Pearson product-moment correlation coefficient (the default) or the Spearman rank-order correlation coefficient. In both cases the absolute value of the correlation is maximized in order to accept strongly negatively correlated programs.\n",
    "\n",
    "The Spearman correlation is appropriate if your next estimator is going to be tree-based, such as a Random Forest or Gradient Boosting Machine. If you plan to send the new transformed variables into a linear model, it is probably better to stick with the default Pearson correlation.\n",
    "\n",
    "The SymbolicTransformer looks at the final generation of the evolution and picks the best programs to evaluate. The number of programs it will look at is controlled by the hall_of_fame parameter.\n",
    "\n",
    "From the hall of fame, it will then whittle down the best programs to the least correlated amongst them as controlled by the n_components parameter. You may have the top two programs being almost identical, so this step removes that issue. The correlation between individuals within the hall of fame uses the same correlation method, Pearson or Spearman, as used by the evolution process."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}